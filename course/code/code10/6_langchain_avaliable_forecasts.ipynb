{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caeccf07-8af4-45ba-a1b2-873a804454cc",
   "metadata": {},
   "source": [
    "# LangChain Tool Demo: Inspecting Available ICON-D2 Forecast Files\n",
    "\n",
    "This notebook demonstrates how a Large Language Model (LLM) can use\n",
    "**tools** to retrieve *real-world metadata* that it cannot hallucinate:\n",
    "available ICON-D2 2 m temperature forecast files from DWD Open Data.\n",
    "\n",
    "Key idea:\n",
    "- LLMs reason\n",
    "- Tools provide ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c15d95d7-8aae-4663-8b9e-11eb2405cad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# DWD proxy\n",
    "os.environ[\"HTTP_PROXY\"]  = \"http://ofsquid.dwd.de:8080\"\n",
    "os.environ[\"HTTPS_PROXY\"] = \"http://ofsquid.dwd.de:8080\"\n",
    "\n",
    "# Optional but recommended\n",
    "os.environ[\"http_proxy\"]  = os.environ[\"HTTP_PROXY\"]\n",
    "os.environ[\"https_proxy\"] = os.environ[\"HTTPS_PROXY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0969e05-afc7-4df6-8de1-2d998bd7f974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OPENAI_API_KEY loaded\n",
      "✅ LLM initialized\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load environment variables and initialize the OpenAI-backed LLM.\n",
    "\n",
    "This cell:\n",
    "- loads variables from a .env file (using python-dotenv)\n",
    "- checks that OPENAI_API_KEY is available\n",
    "- initializes a deterministic ChatOpenAI model\n",
    "\n",
    "Nothing is stored as memory here:\n",
    "each LLM call remains stateless unless we explicitly pass context.\n",
    "\"\"\"\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "assert api_key and api_key.strip(), \"❌ OPENAI_API_KEY not found in environment\"\n",
    "print(\"✅ OPENAI_API_KEY loaded\")\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(\"✅ LLM initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9b388c7-9e0b-4af3-a8b0-85df2bd36748",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Imports required for tool definitions and data access.\n",
    "\n",
    "This cell:\n",
    "- imports HTTP and regex utilities\n",
    "- imports typing for tool schemas\n",
    "- imports the LangChain tool decorator\n",
    "\n",
    "No LLM logic yet.\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dc4d658-8ee4-487e-9e6c-c85d2b875b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tool: list_icon_d2_t2m_files\n",
    "\n",
    "This tool accesses the DWD Open Data server and returns\n",
    "all available ICON-D2 2m temperature GRIB2 filenames.\n",
    "\n",
    "Responsibilities:\n",
    "- HTTP access\n",
    "- HTML parsing\n",
    "- Returning raw filenames only\n",
    "\n",
    "No interpretation is done here.\n",
    "\"\"\"\n",
    "\n",
    "@tool\n",
    "def list_icon_d2_t2m_files() -> List[str]:\n",
    "    \"\"\"\n",
    "    List available ICON-D2 2m temperature GRIB2 files\n",
    "    from the DWD Open Data server.\n",
    "    \"\"\"\n",
    "    url = \"https://opendata.dwd.de/weather/nwp/icon-d2/grib/00/t_2m/\"\n",
    "    response = requests.get(url, timeout=10)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    filenames = re.findall(\n",
    "        r'icon-d2_germany_icosahedral_single-level_\\d{10}_\\d{3}_2d_t_2m\\.grib2\\.bz2',\n",
    "        response.text\n",
    "    )\n",
    "\n",
    "    return sorted(set(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd42e76d-84aa-4ee4-b471-0db87a4ada74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tool: extract_leadtimes\n",
    "\n",
    "This tool parses forecast lead times from ICON-D2 filenames.\n",
    "\n",
    "Responsibilities:\n",
    "- Filename parsing\n",
    "- Returning structured lead times (e.g. '000', '003', ...)\n",
    "\n",
    "This keeps string parsing out of the LLM.\n",
    "\"\"\"\n",
    "\n",
    "@tool\n",
    "def extract_leadtimes(filenames: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract forecast lead times (e.g. 000, 003, 006)\n",
    "    from ICON-D2 filenames.\n",
    "    \"\"\"\n",
    "    leadtimes = set()\n",
    "\n",
    "    for name in filenames:\n",
    "        match = re.search(r'_(\\d{3})_2d_t_2m\\.grib2\\.bz2$', name)\n",
    "        if match:\n",
    "            leadtimes.add(match.group(1))\n",
    "\n",
    "    return sorted(leadtimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e15ae0f-bdeb-421e-989b-34cb79e67869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tools bound to LLM\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Bind tools to the LLM.\n",
    "\n",
    "This step:\n",
    "- exposes tool schemas to the LLM\n",
    "- does NOT execute any tool\n",
    "- does NOT create memory or state\n",
    "\n",
    "The LLM can now decide to request tool calls.\n",
    "\"\"\"\n",
    "\n",
    "llm_with_tools = llm.bind_tools(\n",
    "    [list_icon_d2_t2m_files, extract_leadtimes]\n",
    ")\n",
    "\n",
    "print(\"✅ Tools bound to LLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d85604a-b438-4e3d-8ebe-8bd257d48896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 116, 'total_tokens': 132, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_c4585b5b9c', 'id': 'chatcmpl-CsozI4CvUDsqVWbVoT5GKIUxKZj5o', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b743d-7707-7351-a56e-0a210db17caf-0', tool_calls=[{'name': 'list_icon_d2_t2m_files', 'args': {}, 'id': 'call_QSMSR7A7HXzglZxitcBrHy5q', 'type': 'tool_call'}], usage_metadata={'input_tokens': 116, 'output_tokens': 16, 'total_tokens': 132, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Ask a question that the LLM cannot answer from training data alone.\n",
    "\n",
    "The correct answer depends on the *current* contents\n",
    "of the DWD Open Data server.\n",
    "\"\"\"\n",
    "\n",
    "query = (\n",
    "    \"What ICON-D2 forecast lead times are currently available \"\n",
    "    \"for 2m temperature?\"\n",
    ")\n",
    "\n",
    "response = llm_with_tools.invoke(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af61823a-7923-4454-8f7f-10118c3b080d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'list_icon_d2_t2m_files',\n",
       "  'args': {},\n",
       "  'id': 'call_QSMSR7A7HXzglZxitcBrHy5q',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Inspect tool calls requested by the LLM.\n",
    "\n",
    "At this point:\n",
    "- no tool has been executed yet\n",
    "- the LLM only emits a structured request\n",
    "\"\"\"\n",
    "\n",
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2dfd058-d62c-47f6-9058-cb0d8ad06746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 49 filenames\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Manually execute the requested tool.\n",
    "\n",
    "This keeps control in the Python runtime:\n",
    "- the LLM does not execute code\n",
    "- tools are called explicitly and safely\n",
    "\"\"\"\n",
    "\n",
    "tool_results = {}\n",
    "\n",
    "for call in response.tool_calls:\n",
    "    if call[\"name\"] == \"list_icon_d2_t2m_files\":\n",
    "        result = list_icon_d2_t2m_files.invoke(call[\"args\"])\n",
    "        tool_results[\"filenames\"] = result\n",
    "        print(f\"Retrieved {len(result)} filenames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1cf15d4-bd48-478e-82dd-6672b9221bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1584, 'prompt_tokens': 1794, 'total_tokens': 3378, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1664}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_c4585b5b9c', 'id': 'chatcmpl-CsozJXzKR8V5OX0xcb0UuEztvWAe4', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b743d-7bbf-76e3-914a-40a4df926c7c-0', tool_calls=[{'name': 'extract_leadtimes', 'args': {'filenames': ['icon-d2_germany_icosahedral_single-level_2025123100_000_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_001_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_002_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_003_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_004_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_005_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_006_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_007_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_008_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_009_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_010_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_011_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_012_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_013_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_014_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_015_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_016_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_017_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_018_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_019_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_020_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_021_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_022_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_023_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_024_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_025_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_026_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_027_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_028_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_029_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_030_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_031_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_032_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_033_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_034_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_035_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_036_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_037_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_038_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_039_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_040_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_041_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_042_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_043_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_044_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_045_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_046_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_047_2d_t_2m.grib2.bz2', 'icon-d2_germany_icosahedral_single-level_2025123100_048_2d_t_2m.grib2.bz2']}, 'id': 'call_A0qkTiu6GfZmGus1Uz5IdWqr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1794, 'output_tokens': 1584, 'total_tokens': 3378, 'input_token_details': {'audio': 0, 'cache_read': 1664}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Feed tool output back to the LLM (correct content type).\n",
    "\n",
    "Important rules:\n",
    "- ToolMessage.content must be a STRING\n",
    "- Structured data must be serialized explicitly (e.g. JSON)\n",
    "- tool_call_id must match the original tool request\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "# Take the first (and only) tool call\n",
    "tool_call = response.tool_calls[0]\n",
    "\n",
    "# Serialize filenames to JSON\n",
    "filenames_json = json.dumps(tool_results[\"filenames\"], indent=2)\n",
    "\n",
    "tool_message = ToolMessage(\n",
    "    name=tool_call[\"name\"],\n",
    "    content=filenames_json,\n",
    "    tool_call_id=tool_call[\"id\"],\n",
    ")\n",
    "\n",
    "# Invoke the LLM again with:\n",
    "# - original AI message\n",
    "# - tool result message\n",
    "response2 = llm_with_tools.invoke(\n",
    "    [\n",
    "        response,\n",
    "        tool_message,\n",
    "    ]\n",
    ")\n",
    "\n",
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fa8784c-e825-4788-a43e-46bc30d7eced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'extract_leadtimes',\n",
       "  'args': {'filenames': ['icon-d2_germany_icosahedral_single-level_2025123100_000_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_001_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_002_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_003_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_004_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_005_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_006_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_007_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_008_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_009_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_010_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_011_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_012_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_013_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_014_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_015_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_016_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_017_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_018_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_019_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_020_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_021_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_022_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_023_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_024_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_025_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_026_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_027_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_028_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_029_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_030_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_031_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_032_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_033_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_034_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_035_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_036_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_037_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_038_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_039_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_040_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_041_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_042_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_043_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_044_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_045_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_046_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_047_2d_t_2m.grib2.bz2',\n",
       "    'icon-d2_germany_icosahedral_single-level_2025123100_048_2d_t_2m.grib2.bz2']},\n",
       "  'id': 'call_A0qkTiu6GfZmGus1Uz5IdWqr',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The LLM now has filenames but still needs interpretation.\n",
    "\n",
    "It should request the lead time extraction tool.\n",
    "\"\"\"\n",
    "\n",
    "response2.tool_calls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "debc072a-14c8-4a58-b913-7c336a44eddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " '001',\n",
       " '002',\n",
       " '003',\n",
       " '004',\n",
       " '005',\n",
       " '006',\n",
       " '007',\n",
       " '008',\n",
       " '009',\n",
       " '010',\n",
       " '011',\n",
       " '012',\n",
       " '013',\n",
       " '014',\n",
       " '015',\n",
       " '016',\n",
       " '017',\n",
       " '018',\n",
       " '019',\n",
       " '020',\n",
       " '021',\n",
       " '022',\n",
       " '023',\n",
       " '024',\n",
       " '025',\n",
       " '026',\n",
       " '027',\n",
       " '028',\n",
       " '029',\n",
       " '030',\n",
       " '031',\n",
       " '032',\n",
       " '033',\n",
       " '034',\n",
       " '035',\n",
       " '036',\n",
       " '037',\n",
       " '038',\n",
       " '039',\n",
       " '040',\n",
       " '041',\n",
       " '042',\n",
       " '043',\n",
       " '044',\n",
       " '045',\n",
       " '046',\n",
       " '047',\n",
       " '048']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Execute the second tool: lead time extraction.\n",
    "\n",
    "Again:\n",
    "- explicit execution\n",
    "- deterministic\n",
    "- no hidden control flow\n",
    "\"\"\"\n",
    "\n",
    "leadtimes = extract_leadtimes.invoke(\n",
    "    {\"filenames\": tool_results[\"filenames\"]}\n",
    ")\n",
    "\n",
    "leadtimes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7761dd4-278d-4e26-8fea-73da97a88d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The forecast lead times extracted from the ICON-D2 filenames are as follows:\n",
      "\n",
      "- 000\n",
      "- 001\n",
      "- 002\n",
      "- 003\n",
      "- 004\n",
      "- 005\n",
      "- 006\n",
      "- 007\n",
      "- 008\n",
      "- 009\n",
      "- 010\n",
      "- 011\n",
      "- 012\n",
      "- 013\n",
      "- 014\n",
      "- 015\n",
      "- 016\n",
      "- 017\n",
      "- 018\n",
      "- 019\n",
      "- 020\n",
      "- 021\n",
      "- 022\n",
      "- 023\n",
      "- 024\n",
      "- 025\n",
      "- 026\n",
      "- 027\n",
      "- 028\n",
      "- 029\n",
      "- 030\n",
      "- 031\n",
      "- 032\n",
      "- 033\n",
      "- 034\n",
      "- 035\n",
      "- 036\n",
      "- 037\n",
      "- 038\n",
      "- 039\n",
      "- 040\n",
      "- 041\n",
      "- 042\n",
      "- 043\n",
      "- 044\n",
      "- 045\n",
      "- 046\n",
      "- 047\n",
      "- 048\n",
      "\n",
      "This indicates that the forecast covers a total of 49 lead times from 000 to 048 hours.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Feed the second tool result (lead times) back to the LLM\n",
    "and obtain the final grounded answer.\n",
    "\n",
    "Important:\n",
    "- ToolMessage requires tool_call_id\n",
    "- Tool output must be serialized (JSON)\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "# The LLM requested the second tool in response2\n",
    "tool_call_2 = response2.tool_calls[0]\n",
    "\n",
    "# Serialize lead times\n",
    "leadtimes_json = json.dumps(leadtimes, indent=2)\n",
    "\n",
    "tool_message_2 = ToolMessage(\n",
    "    name=tool_call_2[\"name\"],\n",
    "    content=leadtimes_json,\n",
    "    tool_call_id=tool_call_2[\"id\"],\n",
    ")\n",
    "\n",
    "# Final LLM invocation with:\n",
    "# - previous AI message\n",
    "# - second tool result\n",
    "final_response = llm_with_tools.invoke(\n",
    "    [\n",
    "        response2,\n",
    "        tool_message_2,\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(final_response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07522b36-0cd7-4755-a71d-ae37b85a7b31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(ropy)",
   "language": "python",
   "name": "ropy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
