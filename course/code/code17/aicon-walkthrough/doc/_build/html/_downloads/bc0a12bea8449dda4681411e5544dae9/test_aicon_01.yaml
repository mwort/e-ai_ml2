defaults:
  - diagnostics: evaluation
  - override hydra/job_logging: none
  - override hydra/hydra_logging: none
  - _self_

config_validation: True

data:
  refinement: &refinement 3
  frequency: 6h
  timestep: 6h
  forcing:
    - "HSURF"
    - "FR_LAND"
    - "FR_LAKE"
    - "EMIS_RAD"
    - "SSO_STDH"
    - "SSO_THETA"
    - "SSO_GAMMA"
    - "SSO_SIGMA"
    - "cos_latitude"
    - "sin_latitude"
    - "cos_longitude"
    - "sin_longitude"
    - "cos_julian_day"
    - "sin_julian_day"
    - "cos_local_time"
    - "sin_local_time"
    - "Z0"
    - "insolation"
  normalizer:
    default: mean-std
    min-max: null
    max:
      - "SSO_STDH"
      - "SSO_THETA"
      - "SSO_GAMMA"
      - "SSO_SIGMA"
    none:
      - EMIS_RAD
      - cos_latitude
      - cos_longitude
      - sin_latitude
      - sin_longitude
      - "cos_local_time"
      - "sin_local_time"
    std: []
  imputer:
    default: none
  processors:
    normalizer:
      _target_: anemoi.models.preprocessing.normalizer.InputNormalizer
      config: ${data.normalizer}
  num_features: null
  format: zarr
  diagnostic: []
  remapped:
  remapper:
    default: "none"

hardware:
  paths:
    #data: /shared/data/fe1ai/ml-datasets.new
    data: /hpc/uwork/majacob/ml_datasets
    graph: graph
    output: output_training/mrl${data.refinement}/
    logs:
      base: ${hardware.paths.output}logs/
      wandb: ${hardware.paths.logs.base}
      mlflow: ${hardware.paths.logs.base}mlflow/
      tensorboard: ${hardware.paths.logs.base}tensorboard/
    checkpoints: "output_training/checkpoint/"
    plots: ${hardware.paths.output}plots/
    profiler: ${hardware.paths.output}profiler/
  files:
    graph: graph${data.refinement}
    warm_start: null
    checkpoint:
      every_n_epochs: anemoi-by_epoch-epoch_{epoch:03d}-step_{step:06d}
      every_n_train_steps: anemoi-by_step-epoch_{epoch:03d}-step_{step:06d}
      every_n_minutes: anemoi-by_time-epoch_{epoch:03d}-step_{step:06d}
  # number of GPUs per node and number of nodes (for DDP)
  accelerator: auto
  num_gpus_per_node: 1
  num_nodes: 1
  num_gpus_per_model: 1

graph:
  overwrite: True
  data: "data"
  hidden: "hidden"
  nodes:
    # ICON mesh
    icon_mesh:
      node_builder:
        _target_: anemoi.graphs.nodes.ICONNodes
        name: "icon_grid_0026_R03B07_G"
        grid_filename: "/shared/data/fe1ai/ml-datasets/structure/01_aicon-graph-files/icon_grid_0026_R03B07_G.nc"
        max_level_multimesh: *refinement
        max_level_dataset: *refinement
    # Data nodes
    data:
      node_builder:
        _target_: anemoi.graphs.nodes.ICONCellGridNodes
        icon_mesh: "icon_mesh"
      attributes: ${graph.attributes.nodes} # options: l1, l2, unit-max, unit-sum, unit-std
    # Hidden nodes
    hidden:
      node_builder:
        _target_: anemoi.graphs.nodes.ICONMultimeshNodes
        icon_mesh: "icon_mesh"
  edges:
    # Processor configuration
    - source_name: ${graph.hidden}
      target_name: ${graph.hidden}
      edge_builders:
        - _target_: anemoi.graphs.edges.ICONTopologicalProcessorEdges
          icon_mesh: "icon_mesh"
      attributes: ${graph.attributes.edges}
    # Encoder configuration
    - source_name: ${graph.data}
      target_name: ${graph.hidden}
      edge_builders:
        - _target_: anemoi.graphs.edges.ICONTopologicalEncoderEdges
          icon_mesh: "icon_mesh"
      attributes: ${graph.attributes.edges}
    # Decoder configuration
    - source_name: ${graph.hidden}
      target_name: ${graph.data}
      edge_builders:
        - _target_: anemoi.graphs.edges.ICONTopologicalDecoderEdges
          icon_mesh: "icon_mesh"
      attributes: ${graph.attributes.edges}
  attributes:
    nodes:
      area_weight:
        _target_: anemoi.graphs.nodes.attributes.SphericalAreaWeights # options: Area, Uniform
        norm: unit-max # options: l1, l2, unit-max, unit-sum, unit-std
        fill_value: 0
    edges:
      edge_length:
        _target_: anemoi.graphs.edges.attributes.EdgeLength
        norm: unit-std
      edge_dirs:
        _target_: anemoi.graphs.edges.attributes.EdgeDirection
        norm: unit-std

model:
  output_mask:
    _target_: anemoi.training.utils.masks.NoOutputMask
  cpu_offload: False

  model:
    _target_: anemoi.models.models.encoder_processor_decoder.AnemoiModelEncProcDec

  keep_batch_sharded: True

  num_channels: 64

  processor:
    _target_: anemoi.models.layers.processor.GraphTransformerProcessor
    _convert_: all
    trainable_size: ${model.trainable_parameters.hidden2hidden}
    sub_graph_edge_attributes: ${model.attributes.edges}
    num_layers: 2
    num_chunks: 1
    cpu_offload: ${model.cpu_offload}
    mlp_hidden_ratio: 4 # GraphTransformer or Transformer only
    num_heads: 16 # GraphTransformer or Transformer only
    qk_norm: False
    layer_kernels: &Linear_Kernel
      Linear:
        _target_: torch.nn.Linear
        _partial_: true
      Activation:
        _target_: torch.nn.GELU
  encoder:
    _target_: anemoi.models.layers.mapper.GraphTransformerForwardMapper
    _convert_: all
    trainable_size: ${model.trainable_parameters.data2hidden}
    sub_graph_edge_attributes: ${model.attributes.edges}
    num_chunks: 2
    cpu_offload: ${model.cpu_offload}
    mlp_hidden_ratio: 4 # GraphTransformer or Transformer only
    num_heads: 16 # GraphTransformer or Transformer only
    qk_norm: False
    layer_kernels:
      <<: *Linear_Kernel
  decoder:
    _target_: anemoi.models.layers.mapper.GraphTransformerBackwardMapper
    _convert_: all
    trainable_size: ${model.trainable_parameters.hidden2data}
    sub_graph_edge_attributes: ${model.attributes.edges}
    num_chunks: 1
    cpu_offload: ${model.cpu_offload}
    mlp_hidden_ratio: 4 # GraphTransformer or Transformer only
    num_heads: 16 # GraphTransformer or Transformer only
    qk_norm: False
    initialise_data_extractor_zero: False
    layer_kernels:
      <<: *Linear_Kernel
  trainable_parameters:
    data: 8
    hidden: 8
    data2hidden: 0
    hidden2data: 0
    hidden2hidden: 0
  attributes:
    edges:
      - edge_length
      - edge_dirs
    nodes: []
  # Bounding configuration
  bounding:
    - _target_: anemoi.models.layers.bounding.ReluBounding
      variables: []

training:
  run_id: null
  fork_run_id: null
  load_weights_only: False
  transfer_learning: False # activate to perform transfer learning
  deterministic: false
  precision: 32-true
  multistep_input: 2
  accum_grad_batches: 1
  num_sanity_val_steps: 4
  gradient_clip:
    val: 32.0
    algorithm: value
  swa:
    enabled: false
    lr: 1e-4 # 0.00005
  optimizer:
    zero: False # use ZeroRedundancyOptimizer ; saves memory for larger models
    kwargs:
      betas: [0.9, 0.95]

  model_task: anemoi.training.train.tasks.GraphForecaster
  submodules_to_freeze: []
  strategy:
    _target_: anemoi.training.distributed.strategy.DDPGroupStrategy
    num_gpus_per_model: ${hardware.num_gpus_per_model}
    read_group_size: ${dataloader.read_group_size}

  loss_gradient_scaling: false
  training_loss:
    _target_: anemoi.training.losses.WeightedMSELoss
    scalers: ["pressure_level", "general_variable", "node_weights"]
    ignore_nans: False
  validation_metrics:
    raw_mse:
      _target_: anemoi.training.losses.MSELoss
      scalers: []
      ignore_nans: False
  rollout:
    start: 1
    epoch_increment: 20
    max: 1
  max_epochs: 2
  max_steps: 200
  lr:
    warmup: 1000
    rate: 1e-3
    iterations: 1000
    min: 3.0e-7
  scalers:
    general_variable:
      _target_: anemoi.training.losses.scalers.GeneralVariableLossScaler
      weights:
        default: 1
        U: 0.1
        V: 0.1
        W: 0.1
        QV: 0.5
        P: 15
    pressure_level:
      _target_: anemoi.training.losses.scalers.ReluVariableLevelScaler
      group: ml
      y_intercept: 0.2
      slope: 0.001
    node_weights:
      _target_: anemoi.training.losses.scalers.GraphNodeAttributeScaler
      nodes_name: ${graph.data}
      nodes_attribute_name: area_weight
      norm: unit-sum
  metrics: []
  variable_groups:
    default: sfc
    ml: [P, T, U, V, W]

diagnostics:
  plot:
    asynchronous: True # Whether to plot asynchronously
    datashader: True # Choose which technique to use for plotting
    frequency: # Frequency of the plotting
      batch: 750
      epoch: 5

    # Parameters to plot
    parameters:
      - PS

    # Sample index
    sample_idx: 0

    # Precipitation and related fields
    precip_and_related_fields: [tp, cp]

    callbacks: []

  debug:
    anomaly_detection: false
  checkpoint:
    every_n_minutes:
      save_frequency: 30
      num_models_saved: 3
    every_n_epochs:
      save_frequency: 1
      num_models_saved: -1
    every_n_train_steps:
      save_frequency: 20
      num_models_saved: 0
  log:
    wandb:
      enabled: False
      offline: False
      log_model: False
      project: "Anemoi"
      entity: None
      gradients: False
      parameters: False
    tensorboard:
      enabled: false
    mlflow:
      enabled: false
      offline: True
      log_model: false
      tracking_uri: ""
      experiment_name: "test"
      project_name: AICON
      system: true
      terminal: false
      run_name: "6hr test"
      on_resume_create_child: False
      expand_hyperparams:
        - config
    interval: 1
  enable_checkpointing: True
  enable_progress_bar: false
  print_memory_summary: false

dataloader:
  prefetch_factor: 1
  pin_memory: True
  read_group_size: ${hardware.num_gpus_per_model}
  validation_rollout: 1
  batch_size:
    training: 1
    validation: 1
    test: 1
  limit_batches:
    training: null
    validation: null
    test: 20
  training:
    start: "2022-01-01T00:00:00"
    end: "2022-03-03T00:00:00"
    join: &dataset_files
      - "${hardware.paths.data}/dwd-dream-archive-R03B0${data.refinement}-20220101-20220701-6h-v1-ml14.zarr"
      - "${hardware.paths.data}/dwd-dream-archive-R03B0${data.refinement}-20220101-20220701-6h-v1-forcings.zarr"
      - "${hardware.paths.data}/dwd-dream-archive-R03B0${data.refinement}-20220101-20220701-6h-v1-singlelevel.zarr"
    frequency: ${data.frequency}
    drop: &drop_list [SKT, TQV, VMAX_10M, T_SO_0.0, T_SO_0.005]
  validation:
    join: *dataset_files
    start: "2022-04-01T00:00:00"
    end: "2022-05-01T00:00:00"
    frequency: ${data.frequency}
    drop: *drop_list
  test:
    join: *dataset_files
    start: "2022-05-01T00:00:00"
    end: "2022-06-01T00:00:00"
    frequency: ${data.frequency}
    drop: *drop_list
  num_workers:
    training: 8
    validation: 8
    test: 8
  grid_indices:
    _target_: anemoi.training.data.grid_indices.FullGrid
    nodes_name: ${graph.data}
